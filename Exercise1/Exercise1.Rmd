---
subtitle: "TMA4268 Statistical Learning V2023"
title: "Compulsory exercise 1: Group 3"
author: "Helle Villmones Haug, Hjalmar Jacob Vinje and Sanna Baug Warholm"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  # html_document
  pdf_document
---
  
```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      cache=TRUE, size="scriptsize",fig.width=4, fig.height=3,fig.align = "center")
```

```{r,eval=FALSE,echo=FALSE}
install.packages("knitr")     # probably already installed
install.packages("rmarkdown") # probably already installed
install.packages("ggplot2")   # plotting with ggplot2
install.packages("dplyr")     # for data cleaning and preparation
install.packages("tidyr")     # also data preparation
install.packages("carData")   # dataset
install.packages("class")     # for KNN
install.packages("pROC")      # calculate roc
install.packages("plotROC")   # plot roc
install.packages("ggmosaic")  # mosaic plot
```

```{r,eval=TRUE,echo=FALSE}
library("knitr")
library("rmarkdown")
```

<!--  Etc (load all packages needed). -->


# Problem 1

For this problem you will need to include some LaTex code. Please install latex on your computer and then consult Compulsor1.Rmd for hints how to write formulas in LaTex.

## a)



## b)

## c)

## d)

## e)

 

# Problem 2

## a)

### i) 

### ii)


## b) 

## c)


# Problem 3

The Bigfoot Field Researchers Organization (BFRO)-problem, using the suggested code:

```{r,  eval=TRUE, echo= TRUE}
bigfoot_original <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-09-13/bigfoot.csv")

library(dplyr)

# Prepare the data:
bigfoot <- bigfoot_original %>%
  # Select the relevant covariates:
  dplyr::select(classification, observed, longitude, latitude, visibility) %>%
  # Remove observations of class C (these are second- or third hand accounts):
  dplyr::filter(classification != "Class C") %>%
  # Turn into 0/1, 1 = Class A, 0 = Class B:
  dplyr::mutate(class = ifelse(classification == "Class A", 1, 0)) %>%
  # Create new indicator variables for some words from the description:
  dplyr::mutate(fur = grepl("fur", observed),
                howl = grepl("howl", observed),
                saw = grepl("saw", observed),
                heard = grepl("heard", observed)) %>%
  # Remove unnecessary variables:
  dplyr::select(-c("classification", "observed")) %>%
  # Remove any rows that contain missing values:
  tidyr::drop_na()

```

```{r}

set.seed(2023)
# 70% of the sample size for training set
training_set_size <- floor(0.7 * nrow(bigfoot))
train_ind <- sample(seq_len(nrow(bigfoot)), size = training_set_size)
train <- bigfoot[train_ind, ]
test <- bigfoot[-train_ind, ]
```

## Task a)
### (i) 


```{r}

model <- glm(class~longitude+latitude+visibility+fur+howl+saw+heard, family="binomial", data=train)

glm_probabilities <- predict(model, test, type="response")
no_classified = sum(glm_probabilities >= 0.5)
no_classified # Number of reports classified as clear sightings: 441
```
Number of clear sightings: 441


### (ii)

```{r, echo=TRUE}
summary(model)
```

The coefficients for sawTRUE is 1.29, which means that the average change in log odds with one unit increase of the value.
```{r, echo=TRUE}
change <- exp(1.29)
print(change)
```

The answer is therefore D) Multiply by 3.64")


## Task b)
### (i)

```{r, echo=TRUE}
require(MASS)
qda_model <- qda(class~longitude+latitude+visibility+fur+howl+saw+heard, data=train)
qda_predicted <- predict(qda_model, test)
table(qda_predicted$class) 
```
Number of clear sightings: 626


### (ii) 

1): True,
2): False,
3): False,
4): False


## Task c)
### (i)

```{r, echo=TRUE}
require(class)
?knn()
knn_model <- knn(train=train, test=test, cl=train$class, k=25, prob=TRUE)

table(knn_model)
```
Number of clear sightings: 441


## Task c)
### (ii) 

Trade-off between bias and variance, higher k -> less variance and more bias. How to tune the k-parameter in a better way:  I could create plots for different k-values and choose the k-value with the lowest error.


## Task d)
### (i)

Prediction, because we use existing data for creating a model that will classify a new instance correctly as often as possible. With inference, we are more interested in evaluating the relationship between the response variables and the predictor, i.e. the interepretability of the model. All models are interesting with predicting, but KNN and QDA would not been as relevant for inference.


### (ii)

Sensitivity: True positive value, probability of a positive test result, given that instance truly is positive.
Specificity: True negative value, probability of a negative test result, given that instance tryly is negative.

For all confusion matrices: rows show prediction values and columns show true values.

```{r}
# Confusion matrix Glm
glm_predicted <- rep(0, 912)
glm_predicted[glm_probabilities > 0.5] <- 1
table(glm_predicted, test$class)
glm_sensitivity <- 299/(299+148)
glm_specificity <- 323/(323+142)
glm_sensitivity
glm_specificity
```
Glm sensitivity is 66,9 % and specificity is 69,5 %

```{r}
# Confusion matrix QDA
table(qda_predicted$class, test$class) 
qda_sensitivity <- 389/(389+58)
qda_specificity <- 228/(228+237)
qda_sensitivity
qda_specificity
```
QDA sensitivity is 87,0 % and specificity is 49,0 %

```{r}
# Confusion matrix KNN
table(knn_model, test$class) 
knn_sensitivity <- 362/(362+85)
knn_specificity <- 386/(386+79)
knn_sensitivity
knn_specificity
```
KNN sensitivity is 81,0 % and specificity is 83,0 %


### (iii)

````{r}
library(pROC)

glm_roc <- roc(response = test$class, predictor = glm_probabilities)
plot(glm_roc, col="pink", lwd=4, print.auc=TRUE, main="ROC-curve for glm-model")

qda_roc <- roc(response = test$class, predictor = qda_predicted$posterior[,"1"])
plot(qda_roc, col="purple", lwd=4, print.auc=TRUE, main="ROC-curve for qda-model")

knn_probabilities <- ifelse(knn_model == 0, 1 - attributes(knn_model)$prob,attributes(knn_model)$prob)
knn_roc <- roc(response = test$class, predictor = knn_probabilities)
plot(knn_roc, col="turquoise", lwd=4, print.auc=TRUE, main="ROC curve knn-model")
```


### (iv) 

Glm and QDA performs similar for ROC, while KKN performs significantly better. Would therefore choose the KNN-classifier
for this problem.



# Problem 4

## a)


## b) 

(i): False,
(ii): False,
(iii): True,
(iv): False




